<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Mobile3DScanner: An Online 3D Scanner for High-quality Object Reconstruction with a Mobile Device. Published in the Special Issue of TVCG for ISMAR 2021."/>
    <title>Mobile3DScanner: An Online 3D Scanner for High-quality Object Reconstruction with a Mobile Device</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <style>
      body {
        background: #fdfcf9 no-repeat fixed top left;
        font-family:'Open Sans', sans-serif;
      }
    </style>

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col">
            <h2 style="font-size:30px;">Mobile3DScanner: An Online 3D Scanner for High-quality Object Reconstruction with a Mobile Device</h2>
            <h4 style="color:#6e6e6e;"> Special Issue of TVCG for ISMAR 2021</h4>
            <hr>
            <h6> <a target="_blank">Xiaojun Xiang</a><sup>1*</sup>, 
                 <a target="_blank">Hanqing Jiang</a><sup>1*</sup>, 
                <a href="http://www.cad.zju.edu.cn/home/gfzhang/" target="_blank">Guofeng Zhang</a><sup>2*</sup>,
                <a target="_blank">Yihao Yu</a><sup>1</sup>,
                <a target="_blank">Chenchen Li</a><sup>1</sup>,
                <a target="_blank">Xingbin Yang</a><sup>1</sup>,
                <a target="_blank">Danpeng Chen</a><sup>1</sup>,
                <a href="http://www.cad.zju.edu.cn/bao/" target="_blank">Hujun Bao</a><sup>2</sup></h6>
            <p> <sup>1</sup>SenseTime Research&nbsp;&nbsp; 
                <sup>2</sup>State Key Lab of CAD & CG, Zhejiang University
                <br>
                <sup>*</sup> denotes equal contribution
            </p>
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2104.00681.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <h6 style="color:#8899a5"> Mobile3DScanner is capable of scanning a large immovable object such as a “Lion” statue on iPad Pro 2020.</h6>
            <img class="img-fluid" src="images/teaser.png" alt="Mobile3DScanner Teaser" width="93%">
            <br>
            <hr style="margin-top:0px">
            <p class="text-justify">
              We present a novel online 3D scanning system for high-quality object reconstruction with a mobile device, called Mobile3DScanner. Using a mobile device equipped with an embedded RGBD camera, our system provides online 3D object reconstruction capability for users to acquire high-quality textured 3D object models. Starting with a simlutaneous pose tracking and TSDF fusion module, our system allows users to scan an object with a mobile device to get a 3D model for real-time preview. After the real-time scanning process is completed, the scanned 3D model is globally optimized and mapped with multi-view textures as an efficient post- process to get the final textured 3D model on the mobile device. Unlike most existing state-of-the-art systems which can only scan homeware objects such as toys with small dimensions due to the limited computation and memory resources of mobile platforms, our system can reconstruct objects with large dimensions such as statues. We propose a novel visual-inertial ICP approach to achieve real-time accurate 6DoF pose tracking of each incoming frame on the front end, while maintaining a keyframe pool on the back end where the keyframe poses are optimized by local BA. Simultaneously, the keyframe depth maps are fused by the optimized poses to a TSDF model in real-time. Especially, we propose a novel adaptive voxel resizing strategy to solve the out-of-memory problem of large dimension TSDF fusion on mobile platforms. In the post-process, the keyframe poses are globally optimized and the keyframe depth maps are optimized and fused to obtain a final object model with more accurate geometry. The experiments with quantitative and qualitative evaluation demonstrate the effectiveness of the proposed 3D scanning system based on a mobile device, which can successfully achieve online high-quality 3D reconstruction of natural objects with larger dimensions for efficient AR content creation.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Real-time scanning -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col text-center">
            <h3>Real-time Scanning</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" controls autoplay loop="loop" preload="" muted="">
                <source src="videos/sup-1.mp4" type="video/mp4">
            </video>
        </div>
        <div class="col text-center">
            <h3>More Results</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" controls autoplay loop="loop" preload="" muted="">
                <source src="videos/sup-2.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- showcase -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Reconstruction showcase</h3>
            <hr style="margin-top:0px">
            <div class="embed-responsive embed-responsive-16by9">
              <iframe width="640" height="480" src="https://sketchfab.com/playlists/embed?collection=b8cdbcb052f349a9bc6fc2a68e4f2001&autostart=1"
              frameborder="0" allow="autoplay; fullscreen; vr" allowvr=""
              allowfullscreen="" mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe>            
          </div>
            <br>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- system overview -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>System Overview</h3>
            <hr style="margin-top:0px">

            <img class="img-fluid" src="images/system_overview.png" alt="Mobile3DScanner System Overview" width="80%">
            <p class="text-justify"> 
              If a user wants to scan a natural object by our system, the object should be put on a horizontal planar surface such as a desk or the ground. 
              As the user scans the object by a mobile device with a rear RGBD camera, our pipeline tracks 6DoF poses of the object in real-time using a visual-inertial ICP (VI-ICP) approach, 
              which combines IMU and RGBD information to track the 6DoF poses on the front end, while maintaining a keyframe pool on the back end, with a local BA module and a loop closing module to 
              refine poses of all the keyframes. The object is consistently segmented in each keyframe by a spatio-temporal planar surface tracking method. Simultaneously, the incoming depths 
              are fused by the estimated poses to a TSDF model for real-time preview, using an adaptive voxel resizing strategy. When the user finishes scanning, an object model post-processing 
              module is activated to obtain the final object model. In this post-process, the keyframe poses are optimized in a global BA module, and the object depths of each keyframe are optimized by SGM. 
              The optimized keyframe depths are fused by the globally optimized poses to a final TSDF model, followed by Marching Cubes, Poisson Surface Reconstruction (PSR), Shape from Shading (SFS) and Multi-view Texture Mapping to get the final 3D mesh.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>


  <!-- Comparison with state-of-the-art methods -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Comparison with state-of-the-art methods</h3>
            <!--<p class="text-left">
            We qualitatively and quantitatively compare our Mobile3DScanner to other state-of-the-art methods on the generated 3D models of the static objects captured by iPad Pro 2020.
            -->
            <hr style="margin-top:0px">

            <img class="img-fluid" src="images/compare_SOTA.png" alt="Quantitative Comparison" width="90%">
            <p class="text-justify"> 
            Comparison of our Mobile3DScanner with other state-of-the-art methods: (a) Three representative keyframes in case “La Marseillaise”. (b) Open3D. (c) KinectFusion. (d) InfiniTAM. (e) BundleFusion.
              (f) 3D Scanner App. (g) Ours Mobile3DScanner. (h) The GT model aqcuired by a commercial 3D scanner.
            </p>

            <img class="img-fluid" src="images/model_accuracy.png" alt="Qualitative Comparison" width="90%">
            <p class="text-justify"> 
            The RMSEs and MAEs of the reconstruction results by our Mobile3DScanner and other SOTA methods on our four experimental cases captured by iPad Pro 2020, with each object scanned by a commercial 3D scanner as GT.
            </p>

            <img class="img-fluid" src="images/time_consumption.png" alt="Time Consumption" width="90%">
            <p class="text-justify">
            The detailed time consumptions of our Mobile3DScanner in all the substeps of three cases “Deer”, “La Marseillaise” and “Worker” on an iPad Pro 2020, which contain 487 frames, 1098 frames, and 1438 frames respectively.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <hr style="margin-top:0px">
            <img class="img-fluid" src="images/more_result.png" alt="Quantitative Comparison" width="100%">
        </div>
      </div>
    </div>
  </section>
  <br>

  
  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{sun2021neucon,
  title={{NeuralRecon}: Real-Time Coherent {3D} Reconstruction from Monocular Video},
  author={Sun, Jiaming and Xie, Yiming and Chen, Linghao and Zhou, Xiaowei and Bao, Hujun},
  journal={CVPR},
  year={2021}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <!-- ack -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Acknowledgements</h3>
          <hr style="margin-top:0px">
          <p class="text-justify">
            We would like to thank all Reviewers for their encouraging and constructive comments.
            We would like to thank Nan Wang, Chongshan Sheng, Li Zhou, Jianjun Xia, Jusong Zhou, and Di Zhang for their kind helps in the development of the Mobile3DScanner system.
          </p>
      </div>
    </div>
  </div>

  <!-- rec -->
  <!-- 
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Recommendations to other works from our group</h3>
          <hr style="margin-top:0px">
          <p class="text-justify">
            Welcome to checkout our work on Transformer-based feature matching (<a href="http://zju3dv.github.io/loftr">LoFTR</a>) and human reconstruction (<a href="http://zju3dv.github.io/neuralbody">NeuralBody</a> and <a href="http://zju3dv.github.io/Mirrored-Human">Mirrored-Human</a>) in CVPR 2021.
          </p>
      </div>
    </div>
  </div>
  -->


  <footer class="text-center" style="margin-bottom:10px; font-size: medium;">
      <hr>
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the <a href="https://lioryariv.github.io/idr/" target="_blank">website template</a>.
  </footer>

  <script type="text/javascript">
    function changePlaybackSpeed(speed)
        {
            document.getElementById('inspect_vid').playbackRate = speed;
        }
        // changePlaybackSpeed(0.25)

    var demo = document.getElementById("header_vid");
    var startTime;
    var timeout = undefined;
    demo.addEventListener("loadstart", function() {
      startTime = Date.now();
      timeout = setTimeout(function () {
        var demoWarning = document.getElementById("demo-warning");
        var giteeLink = document.createElement("a");
        giteeLink.innerText = "mirror hosted in mainland China";
        giteeLink.href = "https://project-pages-1255496016.cos-website.ap-shanghai.myqcloud.com/neuralrecon/";
        // var bilibiliLink = document.createElement("a");
        // var youtubeLink = document.createElement("a");
        // bilibiliLink.innerText = "BiliBili";
        // bilibiliLink.href = "";
        // youtubeLink.innerText = "YouTube";
        // youtubeLink.href = "";

        demoWarning.append("Loading the videos took too long, you can optionally visit this site in the ", giteeLink, ".");
        // demoWarning.append("Loading the video took too long, you can optionally watch it on Bilibili", bilibiliLink, " or YouTube", youtubeLink, ".");
        clearTimeout(timeout);
        timeout = undefined;
      }, 6000);
    });
    demo.addEventListener("loadeddata", function() {
      if (timeout) {
        clearTimeout(timeout);
        timeout = undefined;
      }
    });
//     var source = document.createElement("source");
//     source.setAttribute("src", "/videos/web-scene2.m4v");
//     source.setAttribute("type", "video/webm");
//     demo.appendChild(source);
  </script>
  <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>
</html>
